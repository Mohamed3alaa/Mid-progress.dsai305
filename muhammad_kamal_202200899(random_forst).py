# -*- coding: utf-8 -*-
"""Muhammad_Kamal_202200899(random forst).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kiNjHDOxeLYIoSSOLm8kYrKYA_ZnOgb0
"""

!pip install ydata-profiling

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import missingno as msno

df = pd.read_csv('/content/diabetes_012_health_indicators_BRFSS2015.csv')
df.head()

df['Diabetes_012'].value_counts()

"""#Data Preprocessing"""

df.isna().sum()

msno.matrix(df)
plt.title('Missing Data Matrix Plot')
plt.show()

df.duplicated().sum()

duplicates = df[df.duplicated(keep=False)]
duplicates

df.drop_duplicates(inplace=True)

df.duplicated().sum()

df.dtypes

df['Diabetes_012'].value_counts()

x=df.drop('Diabetes_012',axis=1)
y=df['Diabetes_012']

y[y == 2] = 1

y.value_counts()

x.info()

for feature in x.columns:
    plt.figure(figsize=(19, 4))
    sns.boxplot(x=x[feature], color='skyblue')
    plt.title(f'Boxplot of {feature}')
    plt.xlabel(feature)
    plt.show()

def handle_outliers(x, col, method='iqr', threshold=1.5):

    if method == 'iqr':
        Q1 = x[col].quantile(0.25)
        Q3 = x[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - threshold * IQR
        upper_bound = Q3 + threshold * IQR
        x = x[(x[col] >= lower_bound) & (x[col] <= upper_bound)]
    elif method == 'zscore':
        from scipy import stats
        z = np.abs(stats.zscore(x[col]))
        x = x[(z < threshold)]
    else:
        raise ValueError("Invalid outlier handling method. Choose 'iqr' or 'zscore'.")

    return x[col]

for col in x.columns:
    x[col] = handle_outliers(x, col, method='iqr')
    plt.figure(figsize=(19, 4))
    sns.boxplot(x=x[col], color='skyblue')
    plt.title(f'Boxplot of {col} (After Outlier Handling)')
    plt.xlabel(col)
    plt.show()

"""#EDA"""

# Correlation Matrix
plt.figure(figsize=(12, 10))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

for col in df.columns:
  plt.figure(figsize=(8, 6))
  sns.histplot(df[col], kde=True)
  plt.title(f'Distribution of {col}')
  plt.show()

correlations = df.corr()['Diabetes_012'].drop('Diabetes_012')

plt.figure(figsize=(10, 6))
correlations.plot(kind='bar')
plt.title('Correlations between Features and Diabetes_012')
plt.xlabel('Features')
plt.ylabel('Correlation Coefficient')
plt.xticks(rotation=45, ha='right')
plt.show()

from ydata_profiling import ProfileReport
profile = ProfileReport(df, title="Pandas Profiling Report")
profile.to_notebook_iframe()

from imblearn.under_sampling import RandomUnderSampler
y.unique()

rus = RandomUnderSampler(random_state=0)
X_under_sampled, y_undersampled = rus.fit_resample(x,y)

reasmpled_data=pd.concat([X_under_sampled,y_undersampled], axis=1)
reasmpled_data

reasmpled_data['Diabetes_012'].unique()

plt.figure(figsize=(8, 6))
sns.countplot(x='Diabetes_012', data=reasmpled_data)
plt.xticks([0, 1], ['0', '1'])
plt.xlabel('Diabetes_012')
plt.ylabel('Numbers')
plt.title('Distribution of Diabetes_012')
plt.show()

for col in reasmpled_data.columns:
    sns.histplot(reasmpled_data[col], bins=50, edgecolor='black')
    plt.title(f'Histogram of {col}')
    plt.xlabel(col)
    plt.xticks(rotation=90)
    plt.show()

"""#Features Selection"""

from sklearn.feature_selection import mutual_info_regression, VarianceThreshold, chi2, f_classif
from sklearn.preprocessing import StandardScaler, MinMaxScaler

feature_names = x.columns
# Standardize the features (required for some techniques)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(x)

"""* Information Gain (Mutual Information)

"""

from sklearn.impute import SimpleImputer
from sklearn.feature_selection import mutual_info_regression

# Assuming 'x' is your DataFrame
# Impute NaN values with the mean of each column
imputer = SimpleImputer(strategy='mean')  # Or choose another strategy
x_imputed = pd.DataFrame(imputer.fit_transform(x), columns=x.columns)

# Now use the imputed data for mutual_info_regression
mi_scores = mutual_info_regression(x_imputed, y)
mi_scores = pd.Series(mi_scores, index=feature_names)
mi_scores.sort_values(ascending=False, inplace=True)

# Plot Information Gain
plt.figure(figsize=(10, 6))
mi_scores.plot(kind="bar", color="teal")
plt.title("Information Gain (Mutual Information)")
plt.xlabel("Features")
plt.ylabel("Mutual Information Score")
plt.show()

"""The output represents the Mutual Information for each feature in a dataset with two features.


Higher Mutual Information values suggest a stronger relationship or dependency between the features and the target variable.

* Chi-square Test (For Classification Only)
"""

# Scale features to a non-negative range using MinMaxScaler
minmax_scaler = MinMaxScaler()
X_non_negative = minmax_scaler.fit_transform(x)

# Binarize the target variable for classification
y_bin = np.where(y > np.median(y), 1, 0)  # Convert to binary classification

X_non_negative = imputer.fit_transform(X_non_negative)


# Compute Chi-square scores
chi2_scores, _ = chi2(X_non_negative, y_bin)
chi2_scores = pd.Series(chi2_scores, index=feature_names)
chi2_scores.sort_values(ascending=False, inplace=True)

# Plot Chi-square Scores
plt.figure(figsize=(10, 6))
chi2_scores.plot(kind="bar", color="orange")
plt.title("Chi-square Test Scores")
plt.xlabel("Features")
plt.ylabel("Chi-square Score")
plt.show()

"""MedInc has a very high Chi-square score, meaning it has the strongest relationship with the target variable.

* Fisher’s Score (For Classification Only)
"""

# Fisher’s Score is not directly available in scikit-learn, so we'll implement it manually.
def fisher_score(x, y):
    classes = np.unique(y)
    overall_mean = np.mean(x, axis=0)
    between_var = np.zeros(x.shape[1])
    within_var = np.zeros(x.shape[1])

    for c in classes:
        X_c = x[y == c]
        mean_c = np.mean(X_c, axis=0)
        n_c = X_c.shape[0]

        between_var += n_c * (mean_c - overall_mean) ** 2
        within_var += np.sum((X_c - mean_c) ** 2, axis=0)

    fisher_scores = between_var / within_var
    return fisher_scores

fisher_scores = fisher_score(X_scaled, y_bin)  # Using binarized target
fisher_scores = pd.Series(fisher_scores, index=feature_names)
fisher_scores.sort_values(ascending=False, inplace=True)

# Plot Fisher’s Scores
plt.figure(figsize=(10, 6))
fisher_scores.plot(kind="bar", color="purple")
plt.title("Fisher’s Score")
plt.xlabel("Features")
plt.ylabel("Fisher’s Score")
plt.show()

"""* Correlation Coefficient"""

# Correlation Coefficient
corr_scores = np.corrcoef(x.T, y)[-1, :-1]  # Correlation with target
corr_scores = pd.Series(corr_scores, index=feature_names)
corr_scores.sort_values(ascending=False, inplace=True)

# Plot Correlation Coefficients
plt.figure(figsize=(10, 6))
corr_scores.plot(kind="bar", color="blue")
plt.title("Correlation Coefficient with Target")
plt.xlabel("Features")
plt.ylabel("Correlation Coefficient")
plt.show()

"""* Variance Threshold

"""

# Variance Threshold
variance_threshold = VarianceThreshold(threshold=0.1)  # Remove low-variance features
X_variance_selected = variance_threshold.fit_transform(x)

# Get selected features
selected_features = variance_threshold.get_support(indices=True)
print("Selected Features (Variance Threshold):", [feature_names[i] for i in selected_features])

"""* ANOVA (F-test)"""

# ANOVA (F-test)
f_scores, _ = f_classif(x_imputed, y)  # ANOVA F-test
f_scores = pd.Series(f_scores, index=feature_names)
f_scores.sort_values(ascending=False, inplace=True)

# Plot ANOVA F-scores
plt.figure(figsize=(10, 6))
f_scores.plot(kind="bar", color="red")
plt.title("ANOVA F-scores")
plt.xlabel("Features")
plt.ylabel("F-score")
plt.show()

from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

estimator = LogisticRegression(max_iter=1000)
selector = RFE(estimator, n_features_to_select=10)
selector = selector.fit(x_imputed, y)

selected_features = x.columns[selector.support_]
print("Top Features Selected by RFE:")
print(selected_features)

# Get the ranking of features from RFE
feature_ranking = selector.ranking_
feature_names = x.columns

# Create a DataFrame for better visualization
ranking_df = pd.DataFrame({'Feature': feature_names, 'Ranking': feature_ranking})

# Sort the DataFrame by ranking
ranking_df = ranking_df.sort_values('Ranking')

# Plot the feature rankings
plt.figure(figsize=(10, 6))
plt.barh(ranking_df['Feature'], ranking_df['Ranking'], color='skyblue')
plt.xlabel("Ranking")
plt.ylabel("Feature")
plt.title("Feature Ranking by RFE")
plt.gca().invert_yaxis()  # Invert y-axis for better readability
plt.show()



"""# Random forst"""

from sklearn.ensemble import  RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import SelectKBest, f_classif

target_column = 'Diabetes_012'
X = df.drop(target_column, axis=1)
y = df[target_column]
if y.dtype == 'object' or y.nunique() <= 10:
    le = LabelEncoder()
    y = le.fit_transform(y)
# Feature selection using SelectKBest
k = 10
selector = SelectKBest(score_func=f_classif, k=k)
X_selected = selector.fit_transform(X,y)
selected_features = X.columns[selector.get_support()]
print(f"Top {k} selected features:\n", selected_features)

X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Using Random Forest Classifier
rf_clf = RandomForestClassifier(n_estimators=60, max_depth=20, random_state=42)
rf_clf.fit(X_train, y_train)
y_pred_rf = rf_clf.predict(X_test)
acc_rf = accuracy_score(y_test, y_pred_rf)
print(f"Random Forest Classifier Accuracy: {acc_rf:.4f}")



from sklearn.metrics import classification_report, confusion_matrix

print(classification_report(y_test, y_pred_rf))


# Confusion matrix
cm = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted 0', 'Predicted 1'],
            yticklabels=['Actual 0', 'Actual 1'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

!pip install lime

from sklearn.ensemble import RandomForestClassifier
rf_clf = RandomForestClassifier(n_estimators=60, max_depth=20, random_state=42)
rf_clf.fit(X_train, y_train)

# Explain with LIME
import lime
import lime.lime_tabular
feature_names = X.columns
class_names = ['0', '1']
X_numpy = X_selected
explainer = lime.lime_tabular.LimeTabularExplainer(
    X_numpy,
    feature_names=feature_names,
    class_names=class_names,
    mode='classification'
)

# Explain the first instance
exp = explainer.explain_instance(X_numpy[0], rf_clf.predict_proba, num_features=4)
exp.show_in_notebook()  # Shows feature importance

