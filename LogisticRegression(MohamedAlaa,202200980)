from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.feature_selection import SelectKBest, f_classif

target_column = 'Diabetes_012'

X = df.drop(target_column, axis=1)
y = df[target_column]

# Encode target if it's categorical
if y.dtype == 'object' or y.nunique() <= 10:
    le = LabelEncoder()
    y = le.fit_transform(y)



# Feature selection using SelectKBest
k = 10
selector = SelectKBest(score_func=f_classif, k=k)
X_selected = selector.fit_transform(X, y)

selected_features = X.columns[selector.get_support()]
print(f"Top {k} selected features:\n", selected_features)

X_df_selected = X[selected_features]

from statsmodels.stats.outliers_influence import variance_inflation_factor

#Multicollinearity 
vif_data = pd.DataFrame()
vif_data["Feature"] = X_df_selected.columns
vif_data["VIF"] = [variance_inflation_factor(X_df_selected.values, i) for i in range(X_df_selected.shape[1])]
print("\nVariance Inflation Factor (VIF):\n", vif_data)

# Outliers
for col in selected_features:
    plt.figure(figsize=(4, 2))
    sns.boxplot(x=X_df_selected[col])
    plt.title(f'Boxplot for {col}')
    plt.tight_layout()
    plt.show()

# to check Linearity 
for col in selected_features:
    plt.figure(figsize=(4, 2))
    sns.regplot(x=X_df_selected[col], y=y, logistic=True, ci=None, line_kws={"color": "red"})
    plt.title(f'Logistic Relationship: {col}')
    plt.tight_layout()
    plt.show()

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


# Logistic Regression model
model = LogisticRegression(max_iter=1000)
model.fit(X_train_scaled, y_train)

# Predictions
y_pred = model.predict(X_test_scaled)

# Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

!pip install lime

import lime
import lime.lime_tabular

feature_names = selected_features
class_names = ['0', '1'] 
X_numpy = X_train_scaled  

explainer = lime.lime_tabular.LimeTabularExplainer(
    X_numpy,
    feature_names=feature_names,
    class_names=class_names,
    mode='classification',
    discretize_continuous=True
)

exp = explainer.explain_instance(X_numpy[0], model.predict_proba, num_features=4)
exp.show_in_notebook()
